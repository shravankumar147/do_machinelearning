{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = '../datasets/optdigits/optdigits_train.csv'\n",
    "test_file = '../datasets/optdigits/optdigits_test.csv.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_labels = [7,1,5]\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(keep_labels)\n",
    "num_hidden = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Total no. of samples: 5620\n",
      "==> Number of input nodes: 64\n",
      "==> Weights Initialized\n"
     ]
    }
   ],
   "source": [
    "train_lines = open(train_file, 'r').readlines()\n",
    "#print train_lines\n",
    "\n",
    "test_lines = open(test_file, 'r').readlines()\n",
    "\n",
    "print \"==> Total no. of samples: %d\" %(np.array(train_lines).shape[0] + np.array(test_lines).shape[0])\n",
    "\n",
    "train_vectors = []\n",
    "train_labels = []\n",
    "test_vectors = []\n",
    "test_labels = []\n",
    "\n",
    "num_input_nodes = len(train_lines[0].strip().split(',')) - 1\n",
    "\n",
    "print \"==> Number of input nodes: %d\" %num_input_nodes\n",
    "count = 0\n",
    "for line in train_lines:\n",
    "    vector = [int(x) for x in line.strip().split(',')]\n",
    "\n",
    "    train_vectors.append(np.array(vector))\n",
    "    train_labels.append(np.array(vector))\n",
    "\n",
    "train_vectors = np.vstack(train_vectors)[:,0:-1]\n",
    "train_labels =  np.vstack(train_labels)[:,-1]\n",
    "if keep_labels is not None:\n",
    "    if len(keep_labels)==2:\n",
    "        num_output_unit = 1\n",
    "    else:\n",
    "        num_output_unit = len(keep_labels)\n",
    "else:\n",
    "    num_output_unit =  np.unique(train_labels).shape[0]\n",
    "\n",
    "weights1 = np.random.randn(num_input_nodes, num_hidden)/float(np.sqrt(num_input_nodes))\n",
    "b1 = np.zeros((num_hidden))\n",
    "weights2 = np.random.randn(num_hidden, num_output_unit)/float(np.sqrt(num_hidden))\n",
    "b2 = np.zeros((num_output_unit))\n",
    "\n",
    "print \"==> Weights Initialized\"\n",
    "for line in test_lines:\n",
    "    vector = [int(x) for x in line.strip().split(',')]\n",
    "\n",
    "    test_vectors.append(np.array(vector))\n",
    "    test_labels.append(np.array(vector))\n",
    "\n",
    "\n",
    "test_vectors = np.vstack(test_vectors)[:,0:-1]\n",
    "test_labels =  np.vstack(test_labels)[:,-1]\n",
    "\n",
    "\n",
    "# Make labels to categorical labels and filter out the labels\n",
    "if keep_labels is not None:\n",
    "    where_keep_labels = []\t\n",
    "    for l in keep_labels:\n",
    "        where_keep_labels.extend(list(np.where(train_labels==l)[0]) )\n",
    "\n",
    "    n_data = np.sum([wkl.size for wkl in where_keep_labels])\n",
    "    n_keep_labels = len(keep_labels)\n",
    "\n",
    "    original_train_vectors = train_vectors.copy()\n",
    "    train_vectors = np.zeros((n_data,num_input_nodes))\n",
    "\n",
    "else:\n",
    "    n_data = train_vectors.shape[0]\n",
    "    n_keep_labels = np.max(train_labels)+1\n",
    "\n",
    "train_labels_cat = np.zeros((n_data, n_keep_labels))\n",
    "filtered_labels = np.zeros((n_data))\n",
    "\n",
    "count = 0\n",
    "for i in range(train_labels.shape[0]):\n",
    "    if keep_labels is not None :\n",
    "        if train_labels[i] in keep_labels:\n",
    "            train_vectors[count,:] = original_train_vectors[i,:]\n",
    "\n",
    "            #self.train_labels_cat[count,self.train_labels[i]- min(keep_labels)] = 1\n",
    "            filtered_labels[count] = train_labels[i]\n",
    "            count +=1\n",
    "    else:\n",
    "        train_labels_cat[i,train_labels[i]] = 1\n",
    "\n",
    "train_filtered_labels_encoded = le.transform(filtered_labels)\n",
    "\n",
    "for i in range(train_filtered_labels_encoded.shape[0]):\n",
    "    train_labels_cat[i, train_filtered_labels_encoded[i]] = 1\n",
    "\n",
    "def sigmoid(x):\n",
    "\treturn 1/(1 + np.exp(-x))\n",
    "def predict(train_vectors):\n",
    "        # Forward Pass\n",
    "        predictions = []\n",
    "        for x in range(train_vectors.shape[0]):\n",
    "            a_1 = sigmoid(np.matmul((weights1).T, train_vectors[x,:])[:,np.newaxis]+self.b1[:,np.newaxis])\t\n",
    "\n",
    "            a_2 = sigmoid(np.matmul(weights2.T, a_1)+b2[:, np.newaxis])\n",
    "            predictions.append(np.argmax(a_2, axis = 0))\n",
    "\n",
    "\n",
    "        predictions =  np.vstack(predictions)[:,0] \n",
    "        #\n",
    "\n",
    "        accuracy = np.sum(predictions == self.train_filtered_labels_encoded)/float(np.shape(self.train_filtered_labels_encoded)[0])\n",
    "        #pdb.set_trace()\n",
    "        print \n",
    "        \n",
    "\n",
    "def run( max_epochs=100, lr_rate=0.01):\n",
    "\n",
    "    for i in range(max_epochs):\n",
    "        train_Samples_num = X_train.shape[0]\n",
    "        shuffled_indices = random.sample(range(train_Samples_num), train_Samples_num)\n",
    "\n",
    "        for x in shuffled_indices:\n",
    "\n",
    "            # Forward Pass\n",
    "            # a_1 = sigmoid(X_train[x].dot(weights1)+b1)\t\t\n",
    "\n",
    "            # print weights1.shape, X_train[x].shape, np.matmul((weights1).T, X_train[x]).shape, b1.shape\n",
    "            a_1 = sigmoid(np.matmul((weights1).T, X_train[x])[:,np.newaxis]+b1[:,np.newaxis])\t\n",
    "            #print a_1.shape, weights2.shape, b2[np.newaxis,:].shape\n",
    "\n",
    "            # print a_1.shape, weights2.shape\n",
    "\n",
    "            a_2 = sigmoid(np.matmul(weights2.T, a_1)+b2[:, np.newaxis])\n",
    "            #print a_1.shape, a_2.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Backpropagation\n",
    "            #print (train_labels_cat[x][:, np.newaxis] - a_2).shape, (a_2*(1-a_2)).shape\n",
    "            # print (train_labels_cat[x][:,np.newaxis].shape), (a_2).shape,(a_2*(1-a_2)).shape\t\t\t# \t#delta_2 = np.linalg.norm(train_labels_cat[x] - a_2)*((a_2*((1-a_2))))\n",
    "            # pdb.set_trace()\n",
    "            delta_2 = (a_2 - train_labels_cat[x][:, np.newaxis] )*(a_2*(1-a_2))\n",
    "            #print delta_2.shape\n",
    "\n",
    "\n",
    "            dE_dw_2 = np.matmul(a_1, delta_2.T)\n",
    "\n",
    "            dE_db_2 = (delta_2)\n",
    "            # print delta_2\n",
    "\n",
    "\n",
    "\n",
    "        # # \tdelta_1 = (a_1*(1-a_1))*(np.matmul(delta_2,weights2.T))\n",
    "        # \t#print delta_2[:,np.newaxis].shape, weights2.shape\n",
    "            delta_1 = (a_1*(1-a_1))*np.matmul(weights2, delta_2)\n",
    "\n",
    "            dE_dw_1 = np.matmul(X_train[x][:,np.newaxis], delta_1.T)\t\t\t\t\n",
    "        #  \t#print delta_1.shape, X_train[x][:,np.newaxis].shape, dE_dw_1.shape\n",
    "            dE_db_1 = (delta_1)\n",
    "\n",
    "            print delta_1\n",
    "\n",
    "            # print dE_db_1.shape, b1.shape\n",
    "\n",
    "        # \t# Update rules\n",
    "\n",
    "        # \t#print weights1.shape, dE_dw_1.shape\n",
    "\n",
    "        # \tprint weights1.shape, weights2.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            weights1 = weights1 - lr_rate*dE_dw_1\n",
    "            b1 = b1 - lr_rate*dE_db_1[:,0]\t\n",
    "\n",
    "\n",
    "            weights2 = weights2 - lr_rate*dE_dw_2\n",
    "            b2 = b2 - lr_rate*dE_db_2[:,0]\n",
    "\n",
    "        # print b1.shape, b2.shape\n",
    "        #print b1\n",
    "\n",
    "        accuracy = predict()        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, ..., 0, 0, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_filtered_labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "\treturn 1/(1 + np.exp(-x))\n",
    "\n",
    "class MLP(object):\n",
    "    def __init__(self, training_string, testing_string):\n",
    "\n",
    "        train_lines = open(training_string, 'r').readlines()\n",
    "        #print train_lines\n",
    "\n",
    "        test_lines = open(testing_string, 'r').readlines()\n",
    "\n",
    "        print \"==> Total no. of samples: %d\" %(np.array(train_lines).shape[0] + np.array(test_lines).shape[0])\n",
    "\n",
    "        self.train_vectors = []\n",
    "        self.train_labels = []\n",
    "        self.test_vectors = []\n",
    "        self.test_labels = []\n",
    "\n",
    "        self.num_input_nodes = len(train_lines[0].strip().split(',')) - 1\n",
    "\n",
    "        print \"==> Number of input nodes: %d\" %self.num_input_nodes\n",
    "        count = 0\n",
    "        for line in train_lines:\n",
    "            vector = [int(x) for x in line.strip().split(',')]\n",
    "\n",
    "            self.train_vectors.append(np.array(vector))\n",
    "            self.train_labels.append(np.array(vector))\n",
    "\n",
    "        self.train_vectors = np.vstack(self.train_vectors)[:,0:-1]\n",
    "        self.train_labels =  np.vstack(self.train_labels)[:,-1]\n",
    "        if keep_labels is not None:\n",
    "            if len(keep_labels)==2:\n",
    "                num_output_unit = 1\n",
    "            else:\n",
    "                num_output_unit = len(keep_labels)\n",
    "        else:\n",
    "            num_output_unit =  np.unique(self.train_labels).shape[0]\n",
    "\n",
    "        self.weights1 = np.random.randn(self.num_input_nodes, num_hidden)/float(np.sqrt(self.num_input_nodes))\n",
    "        self.b1 = np.zeros((num_hidden))\n",
    "        self.weights2 = np.random.randn(num_hidden, num_output_unit)/float(np.sqrt(num_hidden))\n",
    "        self.b2 = np.zeros((num_output_unit))\n",
    "\n",
    "        print \"==> Weights Initialized\"\n",
    "\n",
    "        for line in test_lines:\n",
    "            vector = [int(x) for x in line.strip().split(',')]\n",
    "\n",
    "            self.test_vectors.append(np.array(vector))\n",
    "            self.test_labels.append(np.array(vector))\n",
    "\n",
    "\n",
    "        self.test_vectors = np.vstack(self.test_vectors)[:,0:-1]\n",
    "        self.test_labels =  np.vstack(self.test_labels)[:,-1]\n",
    "\n",
    "\n",
    "        # Make labels to categorical labels and filter out the labels\n",
    "        if keep_labels is not None:\n",
    "            where_keep_labels = []\t\n",
    "            for l in keep_labels:\n",
    "                where_keep_labels.extend(list(np.where(self.train_labels==l)[0]) )\n",
    "\n",
    "            n_data = np.sum([wkl.size for wkl in where_keep_labels])\n",
    "            n_keep_labels = len(keep_labels)\n",
    "\n",
    "            self.original_train_vectors = self.train_vectors.copy()\n",
    "\n",
    "            self.train_vectors = np.zeros((n_data,self.num_input_nodes))\n",
    "\n",
    "        else:\n",
    "            n_data = self.train_vectors.shape[0]\n",
    "            n_keep_labels = np.max(self.train_labels)+1\n",
    "\n",
    "        self.train_labels_cat = np.zeros((n_data, n_keep_labels))\n",
    "        self.filtered_labels = np.zeros((n_data))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        count = 0\n",
    "        for i in range(self.train_labels.shape[0]):\n",
    "            if keep_labels is not None :\n",
    "                if self.train_labels[i] in keep_labels:\n",
    "                    self.train_vectors[count,:] = self.original_train_vectors[i,:]\n",
    "\n",
    "                    #self.train_labels_cat[count,self.train_labels[i]- min(keep_labels)] = 1\n",
    "                    self.filtered_labels[count] = self.train_labels[i]\n",
    "                    count +=1\n",
    "            else:\n",
    "                self.train_labels_cat[i,self.train_labels[i]] = 1\n",
    "\n",
    "        self.train_filtered_labels_encoded = le.transform(self.filtered_labels)\n",
    "\n",
    "        for i in range(self.train_filtered_labels_encoded.shape[0]):\n",
    "            self.train_labels_cat[i, self.train_filtered_labels_encoded[i]] = 1\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "        # Forward Pass\n",
    "        predictions = []\n",
    "        for x in range(self.train_vectors.shape[0]):\n",
    "            a_1 = sigmoid(np.matmul((self.weights1).T, self.train_vectors[x,:])[:,np.newaxis]+self.b1[:,np.newaxis])\t\n",
    "\n",
    "            a_2 = sigmoid(np.matmul(self.weights2.T, a_1)+self.b2[:, np.newaxis])\n",
    "            predictions.append(np.argmax(a_2, axis = 0))\n",
    "\n",
    "\n",
    "        predictions =  np.vstack(predictions)[:,0] \n",
    "        #\n",
    "\n",
    "        accuracy = np.sum(predictions == self.train_filtered_labels_encoded)/float(np.shape(self.train_filtered_labels_encoded)[0])\n",
    "        #pdb.set_trace()\n",
    "        print accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def run(self, max_epochs=100, lr_rate=0.01):\n",
    "\n",
    "        for i in range(max_epochs):\n",
    "            train_Samples_num = self.train_vectors.shape[0]\n",
    "            shuffled_indices = random.sample(range(train_Samples_num), train_Samples_num)\n",
    "\n",
    "            for x in shuffled_indices:\n",
    "\n",
    "                # Forward Pass\n",
    "                # a_1 = sigmoid(self.train_vectors[x].dot(self.weights1)+self.b1)\t\t\n",
    "\n",
    "                # print self.weights1.shape, self.train_vectors[x].shape, np.matmul((self.weights1).T, self.train_vectors[x]).shape, self.b1.shape\n",
    "                a_1 = sigmoid(np.matmul((self.weights1).T, self.train_vectors[x])[:,np.newaxis]+self.b1[:,np.newaxis])\t\n",
    "                #print a_1.shape, self.weights2.shape, self.b2[np.newaxis,:].shape\n",
    "\n",
    "                # print a_1.shape, self.weights2.shape\n",
    "\n",
    "                a_2 = sigmoid(np.matmul(self.weights2.T, a_1)+self.b2[:, np.newaxis])\n",
    "                #print a_1.shape, a_2.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # Backpropagation\n",
    "                #print (self.train_labels_cat[x][:, np.newaxis] - a_2).shape, (a_2*(1-a_2)).shape\n",
    "                # print (self.train_labels_cat[x][:,np.newaxis].shape), (a_2).shape,(a_2*(1-a_2)).shape\t\t\t# \t#delta_2 = np.linalg.norm(self.train_labels_cat[x] - a_2)*((a_2*((1-a_2))))\n",
    "                # pdb.set_trace()\n",
    "                delta_2 = (a_2 - self.train_labels_cat[x][:, np.newaxis] )*(a_2*(1-a_2))\n",
    "                #print delta_2.shape\n",
    "\n",
    "\n",
    "                dE_dw_2 = np.matmul(a_1, delta_2.T)\n",
    "\n",
    "                dE_db_2 = (delta_2)\n",
    "                # print delta_2\n",
    "\n",
    "\n",
    "\n",
    "            # # \tdelta_1 = (a_1*(1-a_1))*(np.matmul(delta_2,self.weights2.T))\n",
    "            # \t#print delta_2[:,np.newaxis].shape, self.weights2.shape\n",
    "                delta_1 = (a_1*(1-a_1))*np.matmul(self.weights2, delta_2)\n",
    "\n",
    "                dE_dw_1 = np.matmul(self.train_vectors[x][:,np.newaxis], delta_1.T)\t\t\t\t\n",
    "            #  \t#print delta_1.shape, self.train_vectors[x][:,np.newaxis].shape, dE_dw_1.shape\n",
    "                dE_db_1 = (delta_1)\n",
    "\n",
    "                print delta_1\n",
    "\n",
    "                # print dE_db_1.shape, self.b1.shape\n",
    "\n",
    "            # \t# Update rules\n",
    "\n",
    "            # \t#print self.weights1.shape, dE_dw_1.shape\n",
    "\n",
    "            # \tprint self.weights1.shape, self.weights2.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                self.weights1 = self.weights1 - lr_rate*dE_dw_1\n",
    "                self.b1 = self.b1 - lr_rate*dE_db_1[:,0]\t\n",
    "\n",
    "\n",
    "                self.weights2 = self.weights2 - lr_rate*dE_dw_2\n",
    "                self.b2 = self.b2 - lr_rate*dE_db_2[:,0]\n",
    "\n",
    "            # print self.b1.shape, self.b2.shape\n",
    "            #print self.b1\n",
    "\n",
    "            accuracy = self.predict()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "\tmlp = MLP(train_file, test_file)\n",
    "\n",
    "\tmlp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-157c9bda2cd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-c413905a581d>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(max_epochs, lr_rate)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mtrain_Samples_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[0mshuffled_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_Samples_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_Samples_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
